{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bd15234",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Using Coco Dataset with Rikai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578bd874",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, size, col\n",
    "from pyspark.sql.types import FloatType, StructField, StructType, IntegerType, ArrayType, StringType\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import numpy as np\n",
    "from rikai.spark.utils import get_default_jar_version\n",
    "\n",
    "version = get_default_jar_version(use_snapshot=True)\n",
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName('rikai-quickstart')\n",
    "    .config('spark.jars.packages', \n",
    "            \"ai.eto:rikai_2.12:{}\".format(version))\n",
    "    .master('local[*]')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286eecf3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preparing Coco Dataset\n",
    "\n",
    "It will download [Fast.ai subset of Coco dataset](https://course.fast.ai/datasets#coco). It might take sometime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184e8a38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download Coco Sample Dataset from Fast.ai datasets\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "if not os.path.exists(\"coco_sample\"):\n",
    "    subprocess.check_call(\"wget https://s3.amazonaws.com/fast-ai-coco/coco_sample.tgz -O - | tar -xz\", shell=True)\n",
    "else:\n",
    "    print(\"Coco sample already downloaded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0e3de0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Convert coco dataset into Rikai format\n",
    "import json\n",
    "from rikai.spark.functions import box2d_from_top_left\n",
    "\n",
    "with open(\"coco_sample/annotations/train_sample.json\") as fobj:\n",
    "    coco = json.load(fobj)\n",
    "    \n",
    "# print(coco.keys())\n",
    "# print(coco[\"categories\"])\n",
    "# print(coco[\"annotations\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e600e6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "categories_df = spark.createDataFrame(coco[\"categories\"])\n",
    "\n",
    "# Make sure that all bbox coordinates are float\n",
    "anno_array = [{\n",
    "    \"image_id\": a[\"image_id\"],\n",
    "    \"bbox\": [float(x) for x in a[\"bbox\"]],\n",
    "    \"category_id\": a[\"category_id\"]\n",
    "} for a in coco[\"annotations\"]]\n",
    "\n",
    "anno_df = (\n",
    "    spark\n",
    "    .createDataFrame(anno_array)\n",
    "    .withColumn(\"box2d\", box2d_from_top_left(\"bbox\"))\n",
    ")\n",
    "\n",
    "# We could use JOIN to replace pycocotools.COCO\n",
    "annotations_df = (\n",
    "    anno_df.join(categories_df, anno_df.category_id == categories_df.id)\n",
    "    .withColumn(\"anno\", F.struct([col(\"box2d\"), col(\"name\"), col(\"category_id\")]))\n",
    "    .drop(\"box\", \"name\", \"id\", \"category_id\")\n",
    "    .groupBy(anno_df.image_id)\n",
    "    .agg(F.collect_list(\"anno\").alias(\"annotations\"))\n",
    ")\n",
    "\n",
    "annotations_df.printSchema()\n",
    "annotations_df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b23e93",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Build Coco dataset with image and annotations in Rikai format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6128c3b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, concat, udf\n",
    "from rikai.types.vision import Image\n",
    "from rikai.types.geometry import Box2d\n",
    "from rikai.spark.functions import to_image, box2d\n",
    "from rikai.spark.types import ImageType, Box2dType\n",
    "\n",
    "images_df = spark \\\n",
    "    .createDataFrame(spark.sparkContext.parallelize(coco[\"images\"])) \\\n",
    "    .withColumn(\n",
    "        \"image\", \n",
    "        to_image(concat(lit(\"coco_sample/train_sample/\"), col(\"file_name\")))\n",
    "    )\n",
    "images_df = images_df.join(annotations_df, images_df.id == annotations_df.image_id) \\\n",
    "    .drop(\"annotations_df.image_id\", \"file_name\", \"id\")\n",
    "images_df.show(5)\n",
    "images_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52340cf5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Inspect Bounding Boxes on an Image\n",
    "\n",
    "row = images_df.where(\"id = 32954\").first()\n",
    "\n",
    "row.image | [anno.box2d for anno in row.annotations]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf0c92e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Write Spark DataFrame into the rikai format.\n",
    "(\n",
    "    images_df\n",
    "    .repartition(4)  # Control the number of files\n",
    "    .write\n",
    "    .format(\"rikai\")\n",
    "    .mode(\"overwrite\")\n",
    "    .save(\"/tmp/rikaicoco/out\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599a1ded",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# This dataset can be directly loaded into Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2092e311",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from rikai.pytorch.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    Dataset(\"/tmp/rikaicoco/out\", columns=[\"image_id\", \"image\"]),\n",
    "    batch_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13b1deb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(iter(data_loader))\n",
    "len(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050f0f95",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data is appropriately converted into pytorch.Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47731bc5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3fa246",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}